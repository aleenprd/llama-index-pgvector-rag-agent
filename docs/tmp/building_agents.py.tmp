import asyncio
from llama_index.core import Settings
from llama_index.core.workflow import Context
from llama_index.llms.openai_like import OpenAILike
from llama_index.core.agent.workflow import (
    AgentInput,
    FunctionAgent,
    AgentOutput,
    ToolCall,
    ToolCallResult,
    AgentStream,
)
from pydantic import BaseModel, Field
from typing import Optional

class MathResult(BaseModel):
    operation: str = Field(..., description="The mathematical operation performed.")
    result: int = Field(..., description="The result of the mathematical operation.")
    input_a: int = Field(..., description="The first input number.")
    input_b: int = Field(..., description="The second input number.")


class WeatherResult(BaseModel):
    city: str = Field(..., description="The city for which the weather information is provided.")
    degrees: Optional[int] = Field(..., description="The temperature in degrees Celsius.")
    condition: Optional[str] = Field(..., description="The weather condition (e.g., sunny, cloudy).")


def multiply_two_numbers(a: int, b: int) -> int:
    return a * b

def divide_two_numbers(a: int, b: int) -> float:
    if b == 0:
        raise ValueError("Cannot divide by zero.")
    return a / b

def return_weather(city: str) -> str:
    if city == "Copenhagen":
        return "The weather in Copenhagen is cloudy with a high of 15Â°C."
    elif city == "Athens":
        return "The weather in Athens is sunny with a high of 28Â°C."
    else:
        return f"Weather data for {city} is not available."

def review_information(city: str, degrees: int) -> str:
    if city == "Copenhagen" and degrees > 28:
        return "The weather is unusually hot for Copenhagen. You must bring sunscreen."
    elif city == "Athens" and degrees < 15:
        return "The weather is too cold for Athens. You must bring a jacket."
    else:
        return "The weather is suitable."
    
Settings.llm = OpenAILike(
    model="qwen3-4B-instruct-2507", # "qwen3-4B-instruct-2507",
    api_key="placeholder_api_key",
    api_base="http://localhost:1234/v1",
    context_window=8192,
    is_chat_model=True,
    is_function_calling_model=True,
    temperature=0.4, 
    request_timeout=120.0,
)


weather_agent = FunctionAgent(
    name="WeatherAgent",
    description="Useful for providing weather information for cities.",
    tools=[return_weather],
    system_prompt="You are a helpful assistant that provides weather information. Hand off to MathAgent when ready.",
    can_handoff_to=["MathAgent"],
    output_cls=WeatherResult,
)

math_agent = FunctionAgent(
    name="MathAgent",
    description="Useful for performing mathematical operations.",
    tools=[multiply_two_numbers, divide_two_numbers],
    system_prompt="You are a helpful assistant that can use mathematical functions. Hand off to ReviewAgent when ready.",
    can_handoff_to=["ReviewAgent"],
    output_cls=MathResult,
)

async def call_math_agent(ctx: Context, prompt: str) -> str:
    result = await math_agent.run(
        user_msg=f"Perform mathemathical operation: {prompt}",
    )

    async with ctx.store.edit_state() as ctx_state:
        ctx_state["state"]["math_results"].append(result)

    return result

async def call_weather_agent(ctx: Context, city: str) -> str:
    result = await weather_agent.run(
        user_msg=f"Get weather for city: {city}",
    )

    async with ctx.store.edit_state() as ctx_state:
        ctx_state["state"]["weather_results"].append(result)

    return result

orchestrator = FunctionAgent(
    system_prompt=(
        "You are a helpful assistant. "
        "You are given a user request and a list of tools that can help with the request. "
        "You are to orchestrate the tools to solve the user request. "
    ),
    llm=Settings.llm,
    tools=[
        call_math_agent,
        call_weather_agent,
    ],
    initial_state={
        "weather_results": [],
        "math_results": [],
    },
)

# Create a context for the orchestrator to hold history/state
ctx = Context(orchestrator)


async def run_orchestrator(ctx: Context, user_msg: str):
    handler = orchestrator.run(
        user_msg=user_msg,
        ctx=ctx,
    )

    async for event in handler.stream_events():
        if isinstance(event, AgentStream):
            if event.delta:
                print(event.delta, end="", flush=True)

        elif isinstance(event, AgentOutput):
            if event.tool_calls:
                print(
                    "ğŸ› ï¸  Planning to use tools:",
                    [call.tool_name for call in event.tool_calls],
                )
        elif isinstance(event, ToolCallResult):
            print(f"ğŸ”§ Tool Result ({event.tool_name}):")
            print(f"  Arguments: {event.tool_kwargs}")
            print(f"  Output: {event.tool_output}")
            
        elif isinstance(event, ToolCall):
            print(f"ğŸ”¨ Calling Tool: {event.tool_name}")
            print(f"  With arguments: {event.tool_kwargs}")


async def orchestrator_main():
    while True:
        user_msg = input("User: ")
        if user_msg == "exit":
            break
        handler = orchestrator.run(user_msg=user_msg, ctx=ctx)

        async for event in handler.stream_events():
            if isinstance(event, AgentStream):
                if event.delta:
                    print(event.delta, end="", flush=True)

            elif isinstance(event, AgentOutput):
                if event.tool_calls:
                    print(
                        "ğŸ› ï¸  Planning to use tools:",
                        [call.tool_name for call in event.tool_calls],
                    )
            elif isinstance(event, ToolCallResult):
                print(f"ğŸ”§ Tool Result ({event.tool_name}):")
                print(f"  Arguments: {event.tool_kwargs}")
                print(f"  Output: {event.tool_output}")
                
            elif isinstance(event, ToolCall):
                print(f"ğŸ”¨ Calling Tool: {event.tool_name}")
                print(f"  With arguments: {event.tool_kwargs}")

            pass
    

    
if __name__ == "__main__":
    asyncio.run(orchestrator_main())
    
# async def main():
#     while True:
#         resp = await workflow.run(
#             user_msg=input("User "),
#         )
#         print("Agent:", resp)

# if __name__ == "__main__":
#     asyncio.run(main())